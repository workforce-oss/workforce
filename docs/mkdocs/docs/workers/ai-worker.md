# AI Worker

An **AI worker** is a type of **worker** that uses a large-language-model to perform a **task**.

## Overview

- **model**: The name of the model to use. The model must be available based on the **credential**.
- **explain_functions**: Whether to send a message when the worker uses a tool.
- **temperature**: The temperature to use when generating text. Lower values are more deterministic, higher values are more creative.
- **max_tokens**: The maximum number of tokens to generate.
- **top_p**: The top p value to use when generating text. Values closer to 1 are more deterministic, values closer to 0 are more creative.

## Behavior

- The **ai-worker** will use the **model** to generate text based on the current **context**. The context is a combination of **channel messages**, **resources**, **variables**, and **tools responses**.

- The **ai-worker** is smart enough to use **tools** at its own discretion, and it does so silently. If you want to know when the **ai-worker** uses a **tool**, set **explain_functions** to true.

- The **ai-worker** is also smart enough to know what outputs the **task** is expecting and will generate appropriate data for those outputs.

- Text generated by the **ai-worker** is streamed in real-time to the **channel**. This allows the **ai-worker** to generate text in a conversational manner and reduce latency.


## Schema
```yaml
worker:
    ...
    type: ai-worker
    variables:
        model: string, required # The name of the model to use (default: gpt-3.5-turbo)
        explain_functions: bool, optional # Whether to send a message when the worker uses a tool
        temperature: float, optional # The temperature to use when generating text (default: 0)
        max_tokens: int, optional # The maximum number of tokens to generate (default: 2048)
        top_p: float, optional # The top p value to use when generating text (default: 1)
```

## Credential

The **ai-worker** requires a **credential** of type **ai-worker**. The **credential** must have the following variables defined:

- **api_token**: The API token for the model provider

The model provider is selected automatically based on the **model** variable.

See the [OpenAI documentation](https://platform.openai.com/account/api-keys) to get an API token.

## Credential Schema
```yaml
credential:
    ...
    type: ai-worker
    variables:
        api_token: string, required # The API token
```


